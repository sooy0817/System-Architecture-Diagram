{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLiNER2 한국어 학습 (Colab Pro GPU)\n",
    "\n",
    "이 노트북은 `klue/roberta-base`를 사용하여 GLiNER2를 한국어 데이터로 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Drive 마운트 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 프로젝트 업로드 또는 클론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: GitHub에서 클론 (GitHub에 올려둔 경우)\n",
    "# !git clone https://github.com/your-username/your-repo.git\n",
    "# %cd your-repo\n",
    "\n",
    "# 방법 2: 로컬 파일 업로드\n",
    "# 왼쪽 파일 탭에서 프로젝트 폴더를 드래그 앤 드롭\n",
    "\n",
    "# 방법 3: Google Drive에서 복사 (Drive 마운트 후)\n",
    "# !cp -r /content/drive/MyDrive/graph_lang /content/\n",
    "# %cd graph_lang\n",
    "\n",
    "print(\"현재 디렉토리:\")\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 필수 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 및 transformers\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install transformers>=4.30.0\n",
    "!pip install accelerate\n",
    "\n",
    "# 한국어 토크나이저\n",
    "!pip install mecab-python3\n",
    "!pip install python-mecab-ko\n",
    "\n",
    "# 기타 필수 패키지\n",
    "!pip install safetensors\n",
    "!pip install tqdm\n",
    "!pip install numpy\n",
    "!pip install huggingface_hub\n",
    "\n",
    "# GLiNER 관련 (gliner 패키지에서 SpanRepLayer 사용)\n",
    "!pip install gliner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MeCab 사전 설치 (한국어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 학습 데이터 확인\n",
    "with open('data/train_ko_2k.jsonl', 'r', encoding='utf-8') as f:\n",
    "    train_samples = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"학습 데이터: {len(train_samples)}개\")\n",
    "print(\"\\n첫 번째 샘플:\")\n",
    "print(json.dumps(train_samples[0], ensure_ascii=False, indent=2))\n",
    "\n",
    "# 검증 데이터 확인\n",
    "try:\n",
    "    with open('data/val.jsonl', 'r', encoding='utf-8') as f:\n",
    "        val_samples = [json.loads(line) for line in f]\n",
    "    print(f\"\\n검증 데이터: {len(val_samples)}개\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n검증 데이터 없음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 하이퍼파라미터\n",
    "TRAIN_DATA = \"data/train_ko_2k.jsonl\"\n",
    "VAL_DATA = \"data/val.jsonl\"  # 없으면 None으로 설정\n",
    "OUTPUT_DIR = \"./output_ko\"\n",
    "BASE_MODEL = \"klue/roberta-base\"  # 한국어 사전학습 모델\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 16  # Colab Pro GPU에 맞게 조정 (V100: 16-32, A100: 32-64)\n",
    "GRADIENT_ACCUMULATION = 1  # 메모리 부족시 2 또는 4로 증가\n",
    "ENCODER_LR = 1e-5\n",
    "TASK_LR = 5e-4\n",
    "SAVE_STEPS = 500\n",
    "EVAL_STEPS = 500\n",
    "LOGGING_STEPS = 100\n",
    "\n",
    "print(f\"학습 데이터: {TRAIN_DATA}\")\n",
    "print(f\"검증 데이터: {VAL_DATA}\")\n",
    "print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n",
    "print(f\"베이스 모델: {BASE_MODEL}\")\n",
    "print(f\"에포크: {NUM_EPOCHS}\")\n",
    "print(f\"배치 크기: {BATCH_SIZE}\")\n",
    "print(f\"Effective 배치 크기: {BATCH_SIZE * GRADIENT_ACCUMULATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델 및 Trainer 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner2.model import Extractor, ExtractorConfig\n",
    "from gliner2.training.trainer import GLiNER2Trainer, TrainingConfig\n",
    "\n",
    "# 모델 초기화 (klue/roberta-base로 새로 만들기)\n",
    "print(f\"모델 초기화: {BASE_MODEL}\")\n",
    "config = ExtractorConfig(\n",
    "    model_name=BASE_MODEL,\n",
    "    max_width=8,\n",
    "    counting_layer=\"count_lstm\",\n",
    "    token_pooling=\"first\"\n",
    ")\n",
    "model = Extractor(config)\n",
    "\n",
    "print(\"\\n모델 파라미터:\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total: {total_params:,}\")\n",
    "print(f\"Trainable: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Config 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = TrainingConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    experiment_name=\"gliner2-ko\",\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
    "    encoder_lr=ENCODER_LR,\n",
    "    task_lr=TASK_LR,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    save_total_limit=3,\n",
    "    save_best=True,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    fp16=True,  # Mixed precision for faster training\n",
    "    num_workers=2,\n",
    "    seed=42,\n",
    "    validate_data=True,\n",
    ")\n",
    "\n",
    "print(\"Training Config:\")\n",
    "print(f\"  Epochs: {training_config.num_epochs}\")\n",
    "print(f\"  Batch size: {training_config.batch_size}\")\n",
    "print(f\"  Effective batch size: {training_config.effective_batch_size}\")\n",
    "print(f\"  Encoder LR: {training_config.encoder_lr}\")\n",
    "print(f\"  Task LR: {training_config.task_lr}\")\n",
    "print(f\"  FP16: {training_config.fp16}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Trainer 생성 및 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Trainer 생성\n",
    "trainer = GLiNER2Trainer(\n",
    "    model=model,\n",
    "    config=training_config,\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"학습 시작!\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# VAL_DATA가 없으면 None으로 설정\n",
    "val_data = VAL_DATA if os.path.exists(VAL_DATA) else None\n",
    "\n",
    "results = trainer.train(\n",
    "    train_data=TRAIN_DATA,\n",
    "    eval_data=val_data,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"학습 완료!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total steps: {results['total_steps']}\")\n",
    "print(f\"Total epochs: {results['total_epochs']}\")\n",
    "print(f\"Total time: {results['total_time_seconds']:.2f}s\")\n",
    "print(f\"Samples/sec: {results['samples_per_second']:.2f}\")\n",
    "print(f\"Best metric: {results['best_metric']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 학습된 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner2 import GLiNER2\n",
    "\n",
    "# 최고 성능 모델 로드\n",
    "best_model_path = f\"{OUTPUT_DIR}/best\"\n",
    "model = GLiNER2.from_pretrained(best_model_path)\n",
    "\n",
    "# 테스트\n",
    "test_text = \"삼성전자는 서울에 본사를 두고 있으며, 이재용 부회장이 경영하고 있다.\"\n",
    "entities = [\"회사명\", \"지역\", \"인물\"]\n",
    "\n",
    "results = model.extract_entities(test_text, entities)\n",
    "\n",
    "print(f\"텍스트: {test_text}\")\n",
    "print(f\"\\n추출된 엔티티:\")\n",
    "for entity in results:\n",
    "    print(f\"  - {entity['label']}: {entity['text']} (score: {entity['score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 모델 다운로드 (로컬로 가져가기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: Google Drive에 저장\n",
    "!cp -r {OUTPUT_DIR}/best /content/drive/MyDrive/gliner2_ko_best\n",
    "print(\"모델이 Google Drive에 저장되었습니다: /content/drive/MyDrive/gliner2_ko_best\")\n",
    "\n",
    "# 방법 2: ZIP으로 압축 후 다운로드\n",
    "!zip -r gliner2_ko_best.zip {OUTPUT_DIR}/best\n",
    "print(\"\\nZIP 파일 생성 완료: gliner2_ko_best.zip\")\n",
    "print(\"왼쪽 파일 탭에서 다운로드하세요.\")\n",
    "\n",
    "# 방법 3: Colab 파일 다운로드\n",
    "from google.colab import files\n",
    "# files.download('gliner2_ko_best.zip')  # 주석 해제하면 자동 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Hugging Face Hub에 업로드 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face 토큰으로 로그인\n",
    "# from huggingface_hub import login\n",
    "# login()\n",
    "\n",
    "# 모델 업로드\n",
    "# model.push_to_hub(\"your-username/gliner2-ko\", private=True)\n",
    "# print(\"모델이 Hugging Face Hub에 업로드되었습니다!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
